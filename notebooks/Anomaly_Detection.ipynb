{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path (adjust if your structure differs)\n",
    "project_root = r\"D:\\Minor Project Ayan\"\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Check it's added correctly\n",
    "print(\"✅ Path added:\", project_root)\n",
    "\n",
    "# Now import the module\n",
    "from utils.c3d_feature_extractor import extract_c3d_features\n",
    "\n",
    "\n",
    "video_path = r\"D:\\Minor Project Ayan\\data\\Abuse001_x264.mp4\"\n",
    "\n",
    "# Save as .npy\n",
    "extract_c3d_features(video_path,\n",
    "                    save_path=r\"D:\\Minor Project Ayan\\data\\C3D_Features\\Abuse001_features.npy\",\n",
    "                    use_cuda=True,\n",
    "                    save_format=\"npy\")\n",
    "\n",
    "# Save as .mat\n",
    "extract_c3d_features(video_path,\n",
    "                    save_path=r\"D:\\Minor Project Ayan\\data\\C3D_Features\\Abuse001_features.mat\",\n",
    "                    use_cuda=True,\n",
    "                    save_format=\"mat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23770686",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.c3d_feature_extractor import extract_c3d_features\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_path = r\"D:\\Minor Project Ayan\\dataset_Extras\"  # Update with your dataset path\n",
    "\n",
    "# Subfolder names for each class\n",
    "subfolders = [\"Stealing\",\"Vandalism\"]\n",
    "\n",
    "# Define the path where the extracted features will be saved\n",
    "output_path = r\"D:\\Minor Project Ayan\\data\\C3D_Features\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Process all videos in the dataset\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "    print(f\"Processing videos from '{subfolder}'...\")\n",
    "\n",
    "    # Iterate over all videos in the subfolder\n",
    "    for video_name in os.listdir(subfolder_path):\n",
    "        video_path = os.path.join(subfolder_path, video_name)\n",
    "        torch.cuda.empty_cache()\n",
    "        # Ensure the file is a video (check file extension)\n",
    "        if video_path.endswith(('.mp4', '.avi', '.mov')):\n",
    "            print(f\"Processing video: {video_name}\")\n",
    "            \n",
    "            # Define the path to save extracted features\n",
    "            save_path = os.path.join(output_path, f\"{subfolder}_{video_name.split('.')[0]}_features.npy\")\n",
    "            \n",
    "            # Extract C3D features and save them\n",
    "            extract_c3d_features(video_path, save_path=save_path, use_cuda=True, save_format=\"npy\")\n",
    "\n",
    "print(\"Feature extraction completed for all videos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92c1f2",
   "metadata": {},
   "source": [
    "Preparing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3be7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory where extracted features are saved\n",
    "features_dir = r\"D:\\Minor Project Ayan\\data\\C3D_Features\"\n",
    "\n",
    "# Output files for binary classification\n",
    "features_output = r\"D:\\Minor Project Ayan\\data\\X_train.npy\"\n",
    "labels_output = r\"D:\\Minor Project Ayan\\data\\y_train.npy\"\n",
    "\n",
    "# Define the class that represents normal activity\n",
    "normal_class = \"Normal\"\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Loop over all .npy feature files\n",
    "for file_name in os.listdir(features_dir):\n",
    "    if not file_name.endswith(\"_features.npy\"):\n",
    "        continue\n",
    "\n",
    "    label_name = file_name.split(\"_\")[0]\n",
    "\n",
    "    # Binary label assignment\n",
    "    if label_name == normal_class:\n",
    "        label = 0  # Normal\n",
    "    else:\n",
    "        label = 1  # Anomaly\n",
    "\n",
    "    feature_path = os.path.join(features_dir, file_name)\n",
    "    features = np.load(feature_path, allow_pickle=True)\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train, dtype=object)  # keep as object if variable length\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Save them\n",
    "np.save(features_output, X_train)\n",
    "np.save(labels_output, y_train)\n",
    "\n",
    "print(f\"[INFO] Saved {len(X_train)} feature arrays and binary labels.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dda578",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load('D:/Minor Project Ayan/data/X_train.npy', allow_pickle=True)\n",
    "y_train = np.load('D:/Minor Project Ayan/data/y_train.npy', allow_pickle=True)\n",
    "\n",
    "# Convert labels to binary: 0 = Stealing, 1 = Vandalism\n",
    "# (This is already done, so you don't need to modify y_train here if it's already correct)\n",
    "\n",
    "# Ensure proper dtype\n",
    "X_train = np.array(X_train.tolist(), dtype=np.float32)  # Convert from object dtype\n",
    "y_train = np.array(y_train, dtype=np.int64)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, unique values: {np.unique(y_train)}\")\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(32, 512), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_dir = \"D:/Minor Project Ayan/models/\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(checkpoint_dir, 'best_model.h5'),  # Save as .h5\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=os.path.join(checkpoint_dir, 'logs'),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=60,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save final model as .h5\n",
    "model.save(os.path.join(checkpoint_dir, 'final_model.h5'))  # Final model as .h5\n",
    "print(\"✅ Model training complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf7e579",
   "metadata": {},
   "source": [
    "Generating Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8366e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data (assuming X_train and y_train are already prepared)\n",
    "# Make sure your data is in the correct dtype (float32)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure that X_train_split and X_val_split are of type float32\n",
    "X_train_split = np.array(X_train_split, dtype=np.float32)\n",
    "X_val_split = np.array(X_val_split, dtype=np.float32)\n",
    "\n",
    "# Verify the shape and dtype\n",
    "print(f\"X_train_split shape: {X_train_split.shape}, dtype: {X_train_split.dtype}\")\n",
    "print(f\"X_val_split shape: {X_val_split.shape}, dtype: {X_val_split.dtype}\")\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('D:/Minor Project Ayan/models/best_model.keras')\n",
    "\n",
    "# Predict probabilities for validation data\n",
    "y_pred_prob = model.predict(X_val_split)\n",
    "\n",
    "# Convert probabilities to class predictions (threshold 0.5)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_val_split, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_split, y_pred))\n",
    "\n",
    "# Calculate AUC - ROC\n",
    "roc_auc = roc_auc_score(y_val_split, y_pred_prob)\n",
    "print(f\"AUC-ROC Score: {roc_auc}\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_val_split, y_pred_prob)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_val_split, y_pred_prob)\n",
    "pr_auc = auc(recall, precision)  # Calculate AUC for Precision-Recall curve\n",
    "print(f\"AUC-PR Score: {pr_auc}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, color='green', label=f'AUC = {pr_auc:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "# Box plot for Precision and Recall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([precision, recall], vert=True, patch_artist=True, labels=['Precision', 'Recall'])\n",
    "plt.title('Precision and Recall Box Plot')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
